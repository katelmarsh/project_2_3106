---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

```{r}
library(jsonlite)
library(tm)
library(qdap)
job_desc <- jsonlite::fromJSON('~/Downloads/indeed_job_descs_2020_09_20.json')
names(job_desc)
job_desc$request_params[[1]] #not na 1
job_desc$job_descriptions[[45]]  # not na 2
len <- function(x) {
  return(length(x))
}

l <- sapply(job_desc$job_descriptions,length)
l_p <- sapply(job_desc$request_params,length)
description <- job_desc$job_descriptions

desc = c()
for (i in 1:length(description)){
  for (j in 1:length(description[[i]])){
    if (is.na(description[[i]][j])){
      next
    }
    desc <- append(desc,description[[i]][j])
  }
}

library(methods)
library(quanteda)
# data("data_corpus_inaugural", package = "quanteda")
d <- quanteda::dfm(desc, verbose = FALSE)

dim(d)

#l <- sapply(desc,len)
#desc_dtm <- DocumentTermMatrix(desc[[1]])
target_freq <- as.numeric(d)
freqs_mat <- as.matrix(d)
doc_freq <- apply(freqs_mat,2,function(x) mean(x>0))
idf <- 1/doc_freq
idf_mat <- rep(idf,nrow(freqs_mat), byrow = TRUE, nrow = nrow(freqs_mat))
tf_idf <- freqs_mat * idf_mat

```


```{r pca}
pr_out <- prcomp(tf_idf, scale=TRUE) #look at names of pr_out 
eigen_val <- pr_out$sdev^2 
plot(cumsum(eigen_val) / sum(eigen_val))
abline(h=.9)
plot(pr_out$sdev)

# data mining approach 
k <- 3 # could be anywhere from 2-4
plot(pr_out$rotation[, k])
head(pr_out$rotation[,k]) #these are the loadings 
abline(h = 0)
which(abs(pr_out$rotation[, k]) > 0.08)
```

The some of the loadings are who, we, are, :, cardinal, and financial. 
NOTE: I am wondering if our word-separation method is the best we could use because the loadings include a lot of things like punctuation marks. 

There are a lot of words with high PCA values. 
NOTE: should we keep the websites in? 
TF-IDF does seem to be important though because it has revealed that the job descriptions are asking for very specific things like "agtech" or "adventurous" very frequently.  


```{r remove stopwords and punctuations}
desc_cleaned <- c()
for (i in seq_along(desc)){
    without_stopwords <- rm_stopwords(
    desc[i],
    stopwords = qdapDictionaries::Top25Words,
    unlist = FALSE,
    separate = TRUE,
    strip = FALSE,
    unique = FALSE,
    char.keep = NULL,
    names = FALSE,
    ignore.case = TRUE,
    apostrophe.remove = FALSE
  )
  combine_1 <- combine_words(
    without_stopwords[[1]],
    sep = " "
  )
  combine =paste("", combine_1,"")
  desc_cleaned <- append(desc_cleaned, removePunctuation(combine))
}

# the dim of d is 590*16202. After removing all the punctuations and stopwords, its dimension is 590*13823.
d_cleaned <- quanteda::dfm(desc_cleaned, verbose = FALSE)

dim(d_cleaned)

#l <- sapply(desc,len)
#desc_dtm <- DocumentTermMatrix(desc[[1]])
target_freq_1 <- as.numeric(d_cleaned)
freqs_mat_1 <- as.matrix(d_cleaned)
doc_freq_1 <- apply(freqs_mat_1,2,function(x) mean(x>0))
idf_1 <- 1/doc_freq_1
idf_mat_1 <- rep(idf_1,nrow(freqs_mat_1), byrow = TRUE, nrow = nrow(freqs_mat_1))
tf_idf_1 <- freqs_mat_1 * idf_mat_1
```

